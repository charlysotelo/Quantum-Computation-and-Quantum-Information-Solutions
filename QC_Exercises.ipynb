{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbb924-2a53-4439-9b06-000b3c5cbd94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install qiskit matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcbbe93-49b2-4f3c-9549-8d40b1a09fe8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Latex commands are defined in this cell\n",
    "$$\\newcommand{\\ket}[1]{\\left|{#1}\\right\\rangle}$$\n",
    "$$\\newcommand{\\bra}[1]{\\left\\langle{#1}\\right|}$$\n",
    "$$\\newcommand{\\braket}[2]{\\left\\langle{#1}\\middle|{#2}\\right\\rangle}$$\n",
    "$$\\renewcommand{\\qed}{\\hfill\\blacksquare}$$\n",
    "$$\\newcommand{\\paulix}{\\begin{bmatrix} 0 && 1 \\\\ 1 && 0\\end{bmatrix}}$$\n",
    "$$\\newcommand{\\pauliy}{\\begin{bmatrix} 0 && -i\\\\ i && 0\\end{bmatrix}}$$\n",
    "$$\\newcommand{\\pauliz}{\\begin{bmatrix} 1 && 0 \\\\ 0 && -1\\end{bmatrix}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80964823-552b-4cd9-bae0-915e90af39a2",
   "metadata": {},
   "source": [
    "# My solutions to exercises and problem sets from \"Quantum Computation and Quantum Information\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a2c34-77d9-424a-a7c4-2d5750f1ae18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises for Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7862ef-1621-4d75-8549-71af5c370622",
   "metadata": {},
   "source": [
    "### Exercise 1.1 (page 36): (Probabilistic classical algorithm)\n",
    "\n",
    "Given $n$ bits, the function $f(x)$ has a domain of size $2^n$. The best classical deterministic algorithm, in the worst case, must check half of all inputs + 1 (that is, $2^n/2 + 1= 2^{n-1}+1$).\n",
    "\n",
    "Consider the probabilistic solution where we do $k$ unique evaluations of the $f(x)$ for unique and randomized $x \\in \\{0,1\\}^n$. If any samples differ from the rest of the samples, we conclude $f(x)$ is balanced, otherwise we conclude it is constant.\n",
    "\n",
    "If $f(x)$ is constant, we will be correct with probability 1. If $f(x)$ is balanced, for the case $k = 2$, there are only 4 possible sampling outcomes: $f(x_1) \\otimes f(x_2)\\in \\{00, 01, 10, 11\\}$. The probability of getting all equal outputs, that is $f(x_1) \\otimes f(x_2) \\in \\{00, 11\\}$ is $\\frac{2^{n-1} - 1}{2^n - 1}$, so we will be incorrect with that probability. For n = 2 its 1/3. In the limit as n approaches infinity, this approaches 1/2\n",
    "\n",
    "In general, given $n, k$, the prob of getting all equal outputs, that is $f(x_1) \\otimes f(x_2) \\otimes ... \\otimes f(x_k) \\in \\{0^k, 1^k\\}$ has probability $\\prod_{i=1}^k \\frac{2^{n-1} - k}{2^n - k}$, so we will be incorrect with that probability. For n = 2 its 1/3. In the limit as n approaches infinity, this approaches 1/2\n",
    "\n",
    "So to answer the question posed by the exercise, the performance of the best classical algorithm for the Deutsch-Jozsa problem is $\\mathcal{O}(1)$, since we can get better than $\\epsilon < 1/2$ with $ k = 2 $ for any n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3258d55-18f2-4721-afbd-79566e19aa05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epsilon(n, k):\n",
    "    \"\"\"\n",
    "    Given the number of bits n and number of samples k, calculate the prob of the above\n",
    "    algorithm being incorrect if f(x) is balanced\n",
    "    \"\"\"\n",
    "    result = k\n",
    "    for x in range(k):\n",
    "        result *= (2**(n-1)-x)/(2**n - x)\n",
    "    return result\n",
    "\n",
    "epsilon(50, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9dc13b-ea5a-44e5-aa1f-750e1d54bcc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 1.2 (page 57): (Cloning and Distinguishability)\n",
    "\n",
    "#### Cloning given Distinguishability\n",
    "\n",
    "Given a circuit that can distinguish between non-orthogonal states: $$\\ket{\\Psi} = e^{i\\gamma}(\\cos\\frac{\\theta}{2}\\ket{0} +e^{i\\phi}\\sin\\frac{\\theta}{2}\\ket{1})$$\n",
    "\n",
    "$$\\ket{\\Phi} = e^{i\\gamma^{\\prime}}(\\cos\\frac{\\theta^{\\prime}}{2}\\ket{0} +e^{i\\phi^{\\prime}}\\sin\\frac{\\theta^{\\prime}}{2}\\ket{1})$$\n",
    "\n",
    "We can build a quantum cloning given below. Note we do this for 1 qubit, but the same procedure can be applied to an n-qubit register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30341ce8-f667-4553-b255-1491aae1d28d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit import *\n",
    "from qiskit.circuit import Parameter\n",
    "from math import pi\n",
    "\n",
    "# Psi\n",
    "psi_theta = Parameter('θ')\n",
    "psi_phi = Parameter('φ')\n",
    "psi_lambda = Parameter('λ')\n",
    "\n",
    "# Phi\n",
    "phi_theta = Parameter('θ`')\n",
    "phi_phi = Parameter('φ`')\n",
    "phi_lambda = Parameter('λ`')\n",
    "\n",
    "# Define our distinguisher oracle\n",
    "distinguisher = QuantumCircuit(1, name=\"distinguisher\")\n",
    "distinguisher.to_instruction()\n",
    "\n",
    "x_qubit = QuantumRegister(1, '|x>')\n",
    "scratch0 = QuantumRegister(1)\n",
    "scratch1 = QuantumRegister(1)\n",
    "\n",
    "circuit = QuantumCircuit(x_qubit, scratch0, scratch1)\n",
    "circuit.append(distinguisher,[0])\n",
    "circuit.reset(1)\n",
    "circuit.reset(2)\n",
    "circuit.cu(psi_theta, psi_phi, psi_lambda, 0, 0, 1)\n",
    "circuit.cu(psi_theta, psi_phi, psi_lambda, 0, 0, 2)\n",
    "circuit.x(0)\n",
    "circuit.cu(phi_theta, phi_phi, phi_lambda, 0, 0, 1)\n",
    "circuit.cu(phi_theta, phi_phi, phi_lambda, 0, 0, 2)\n",
    "circuit.draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a55eb-e9d8-47be-8eaf-90b211604607",
   "metadata": {},
   "source": [
    "Conversely, given a cloning circuit we may distinguish between two states with high probability by repeatedly cloning our state and measuring it in the $\\ket{\\Psi}$ basis a large amount of times. If we measure -1 even once, then we output 0, indicating the original state is $\\ket{\\Phi}$, otherwise we output 1, indicating  $\\ket{\\Psi}$. Note in the below circuit, the inverted U Gate is the adjoint of the above gate. This is just to effectively measure in the $\\ket{0}$ basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e43008-346c-4d9e-b8a9-ff8a86ce28b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import UGate\n",
    "\n",
    "qc = QuantumCircuit(2, 1)\n",
    "\n",
    "cloner = QuantumCircuit(2, name=\"cloner\")\n",
    "cloner.to_instruction()\n",
    "\n",
    "N=100 # The larger the N, the higher the certainty in the result\n",
    "with qc.for_loop(range(N)) as i:\n",
    "    qc.append(cloner, [0,1])\n",
    "    qc.append(UGate(psi_theta, psi_phi, psi_lambda).inverse(), [1]) # Bring from phi-basis to 0-basis\n",
    "    qc.measure(1, 0)\n",
    "    qc.break_loop().c_if(0, 0)\n",
    "qc.draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fae7f7-e9d9-430f-9ea1-3a241d725f9c",
   "metadata": {},
   "source": [
    "## Exercises for Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96253646-ba8b-457f-b93b-8543ca70cee8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 2.1 (page 63): (Linear dependence)\n",
    "\n",
    "Show that the vectors below are linearly dependent\n",
    "\n",
    "$$v_1 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}, v_2 = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, v_3 = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "Recall that N vectors $v_1, v_2, ... v_N$ are lineraly-dependent if there exists $a_1, a_2, ..., a_N$ such that $\\sum_{i=1}^N{a_iv_i} = 0$, where at least one $a_i \\ne 0$\n",
    "\n",
    "Clearly this is the case for $a_1 = 1, a_2 = 1, a_3 = -1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e27b12-451e-4e1c-b223-b806bc804dd2",
   "metadata": {},
   "source": [
    "### Exercise 2.2 (page 64): (Matrix representation)\n",
    "Given a linear operator $A$ which maps $\\ket{0}$ to $\\ket{1}$ and vice-versa, the matrix representation of $A$ in the basis $\\ket{0}$ and $\\ket{1}$ for both the input and output vector spaces is\n",
    "$$A = \\begin{bmatrix} 0 && 1\\\\ 1 && 0\\end{bmatrix}$$\n",
    "\n",
    "To find $A$ for different input and output basis, say $\\ket{+}$ and $\\ket{-}$, we can simply find the matrix $S$ which transforms from the ($\\ket{+}$, $\\ket{-}$) basis to the ($\\ket{0}$, $\\ket{1}$).\n",
    "\n",
    "Trivially, this is $$ S = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 && 1\\\\ 1 && -1\\end{bmatrix}$$\n",
    "\n",
    "We may then construct the matrix $A^\\prime = S^{\\dagger}AS$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c180565-8796-4e09-836e-ec17bca7a1c5",
   "metadata": {},
   "source": [
    "### Exercise 2.3 (page 64): (Matrix representation for operator products)\n",
    "Show the matrix representation for linear transformation $BA$ is the matrix product of the matrix representation for $B$ and $A$, with respect to the approriate bases.\n",
    "\n",
    "$$A: V \\rightarrow W$$\n",
    "$$B: W \\rightarrow X$$\n",
    "\n",
    "$V$, $W$, and $X$ have basis vectors $\\ket{v_i}$, $\\ket{w_j}$, and $\\ket{x_k}$ respectively, such that\n",
    "\n",
    "$$A\\ket{v_i} = \\sum_j{A_{ji}\\ket{w_j}}$$\n",
    "$$B\\ket{w_j} = \\sum_k{B_{kj}\\ket{x_k}}$$\n",
    "\n",
    "therefore\n",
    "$$ BA\\ket{v_i} = B(A\\ket{v_i}) = B(\\sum_j{A_{ji}\\ket{w_j}}) = \\sum_j{A_{ji}B\\ket{w_j}} = \\sum_j{A_{ji}\\sum_k{B_{kj}\\ket{x_k}}} = \\sum_k{\\ket{x_k}\\sum_j{B_{kj}A_{ji}}} = \\sum_k{BA_{ki}\\ket{x_k}}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ BA_{ki} = \\sum_j{B_{kj}A_{ji}}$$\n",
    "\n",
    "which is the matrix product of $B$ and $A$ by definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd0867-b915-4fe1-99e9-c4692db463e7",
   "metadata": {},
   "source": [
    "### Exercise 2.4 (page 65): (Matrix representation for identity)\n",
    "Show the identity operator $I: V \\rightarrow V$ has a matrix representation of $\\delta_{ij}$ when acting on the same input and output basis\n",
    "\n",
    "Define the basis for vector space $V$ to be $\\ket{v_i}$ (which we know must always exist). Note: $I\\ket{v} \\equiv \\ket{v}$. The matrix representation of $I$ is one that satisfies:\n",
    "\n",
    "$$I\\ket{v_j} = \\sum_k{I_{kj}\\ket{v_k}}$$\n",
    "\n",
    "We take the inner product with $\\ket{v_i}$\n",
    "\n",
    "$$ \\braket{v_i|v_j} = \\delta_{ij} =\\bra{v_i} \\sum_k{I_{kj}\\ket{v_k}} = \\sum_k{I_{kj}\\braket{v_i|v_k}} = \\sum_k{I_{kj}\\delta_{ik}} = I_{ij}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25cee09-27f8-4003-a129-76bae11a15f8",
   "metadata": {},
   "source": [
    "### Exercise 2.5 (page 66): (Verify (.,.) is an inner product on $\\bf{C^n}$)\n",
    "\n",
    "The three requirements of an inner product $(a, b)$ are:\n",
    "1. $(a, \\alpha b + \\beta c) = \\alpha(a, b) +\\beta (a, c)$ (that is, linear in its second argument)\n",
    "2. $(a, b) = (b, a)^*$\n",
    "3. $(a, a) \\ge 0 $ with equality iff $a = 0$\n",
    "\n",
    "\n",
    "Verify these are met for the inner product on $\\bf{C^n}$ defined as:\n",
    "$$ ((y_1,...,y_n),(z_1,...,z_n)) = \\sum_i{y_i^*z_i} = \\begin{bmatrix} y_1^* \\ ... \\ y_n^* \\end{bmatrix} \\begin{bmatrix} z_1 \\\\ \\vdots \\\\ z_n \\end{bmatrix} $$\n",
    "\n",
    "1. $(a, \\alpha b + \\beta c) =  \\sum_i{a_i^*(\\alpha b_i + \\beta c_i)} = \\sum_i{a_i^*\\alpha b_i + a_i^*\\beta c_i} = \\alpha \\sum_i{a_i^*b_i} + \\beta \\sum_i{a_i^*c_i} = \\alpha(a, b) + \\beta (a, c)$\n",
    "\n",
    "2. $(a, b) = \\sum_i{a_i^*b_i} = (\\sum_i{b_i^*a_i})^* = (b, a)^*$\n",
    "\n",
    "3. $(a, a) = \\sum_i{a_i^*a_i} = \\sum_i{|a_i|^2}$ (finite sum of positive numbers is always positive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc8b93-5d35-4584-8d4f-eb1575c4ca53",
   "metadata": {},
   "source": [
    "### Exercise 2.6 (page 66): (Verify any (.,.) is conjugate-linear in first argument)\n",
    "\n",
    "Prove $$(\\alpha a + \\beta b, c) = \\alpha^* (a, c) + \\beta^* (b, c)$$\n",
    "\n",
    "By point 2: $$(\\alpha a + \\beta b, c) = (c, \\alpha a + \\beta b)^*$$\n",
    "\n",
    "By point 1: $$(c, \\alpha a + \\beta b)^* =  (\\alpha (c, a) + \\beta (c, b))^* = \\alpha^* (c, a)^* + \\beta^* (c, b)^*$$\n",
    "\n",
    "By point 2: $$\\alpha^* (c, a)^* + \\beta^* (c, b)^* = \\alpha^* (a, c) + \\beta^* (b, c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f034a-41f9-4082-868b-b53b52a3a958",
   "metadata": {},
   "source": [
    "### Exercise 2.7 (page 66): (Verify orthogonality of $\\ket{w} = (1,1)$ and $\\ket{v} = (1, -1)$)\n",
    "\n",
    "Also show the normalized versions.\n",
    "\n",
    "$$(\\ket{w}, \\ket{v}) = \\begin{bmatrix} 1^* \\ 1^* \\end{bmatrix} \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} = 0$$\n",
    "\n",
    "\n",
    "$$ \\frac{\\ket{w}}{||\\ket{w}||} = \\frac{\\ket{w}}{\\sqrt{\\braket{w}{w}}} = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $$\n",
    "\n",
    "$$ \\frac{\\ket{v}}{||\\ket{v}||} = \\frac{\\ket{v}}{\\sqrt{\\braket{v}{v}}} = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4642dfe4-1c36-4c68-b1c7-01ac695555e8",
   "metadata": {},
   "source": [
    "### Exercise 2.8 (page 66): (Prove Gram-Schmidt produces an orthonomral basis for V)\n",
    "\n",
    "$$\\ket{v_{k+1}} = \\frac{\\ket{w_{k+1}} -\\sum_{i=1}^{k}{\\braket{v_i}{w_{k+1}} \\ket{v_i}}}{|| \\ket{w_{k+1}} - \\sum_{i=1}^{k}{\\braket{v_i}{w_{k+1}} \\ket{v_i}} ||} $$\n",
    "\n",
    "We prove the above by induction. Base case:\n",
    "\n",
    "$$\\ket{v_1} = \\frac{\\ket{w_1}}{|| \\ket{w_1} ||}$$\n",
    "\n",
    "It is trivially unit length and linearly-independent.\n",
    "\n",
    "Inductive step: Assume $\\{\\ket{v_i}: i < k\\}$ for $i < k$ is an orthonormal basis, we show $\\{\\ket{v_i}: i \\le k\\}$ is also an orthonormal basis:\n",
    "\n",
    "\n",
    "It is trivial to see $\\ket{v_{k+1}}$ is of unit length, as the vector is scaled by the reciprocal of its length. Therefore all we have to do is show orthogonality with all other vectors in the basis, so we ignore the normalization factor:\n",
    "\n",
    "$$\\ket{v_{k+1}}  \\propto \\ket{w_{k+1}} -\\sum_{i=1}^{k}{\\braket{v_i}{w_{k+1}} \\ket{v_i}}$$\n",
    "\n",
    "And so \n",
    "\n",
    "$$\\braket{v_j}{v_{k+1}} \\propto \\braket{v_j}{w_{k+1}} -\\sum_{i=1}^{k}{\\braket{v_i}{w_{k+1}} \\braket{v_j}{v_i}} $$\n",
    "\n",
    "$$\\braket{v_j}{v_{k+1}} \\propto \\braket{v_j}{w_{k+1}} -\\sum_{i=1}^{k}{\\braket{v_i}{w_{k+1}} \\delta_{ji}}$$\n",
    "\n",
    "$$\\braket{v_j}{v_{k+1}} \\propto \\braket{v_j}{w_{k+1}} -\\braket{v_j}{w_{k+1}}$$\n",
    "\n",
    "$$\\braket{v_j}{v_{k+1}} \\propto 0$$\n",
    "\n",
    "$$\\braket{v_j}{v_{k+1}} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980498f4-1511-4b21-ac59-50d4c945b270",
   "metadata": {},
   "source": [
    "### Exercise 2.9 (page 68): (Pauli Operators and Outer Product)\n",
    "\n",
    "Express all 4 Pauli matrices ($\\sigma_0$, $\\sigma_1$, $\\sigma_2$, $\\sigma_3$) in the outer product  with respect to the ($\\ket{0}$, $\\ket{1}$) basis:\n",
    "\n",
    "$$I = \\sum_{i=0}^1{\\ket{i} \\bra{i}}$$\n",
    "\n",
    "$$\\sigma_i = I\\sigma_kI = \\sum_{ij}{\\bra{j} \\sigma_k \\ket{i} \\ket{j} \\bra{i}}$$ \n",
    "\n",
    "$$\\sigma_0 = \\sum_{ij}{\\bra{j} \\sigma_0 \\ket{i} \\ket{j} \\bra{i}} = \\sum_{ij}{\\delta_{ij} \\ket{j} \\bra{i}} = \\sum_{i}{\\ket{i} \\bra{i}}$$\n",
    "\n",
    "$$\\sigma_1 = \\sum_{ij}{\\bra{j} \\sigma_1 \\ket{i} \\ket{j} \\bra{i}} = \\sum_{ij}{\\ket{j} \\bra{i}}$$ \n",
    "\n",
    "$$\\sigma_2 = \\sum_{ij}{\\bra{j} \\sigma_2 \\ket{i} \\ket{j} \\bra{i}} = \\sum_{ij}{(-1)^ii \\ket{j} \\bra{i}}$$ \n",
    "\n",
    "$$\\sigma_3 = \\sum_{ij}{\\bra{j} \\sigma_3 \\ket{i} \\ket{j} \\bra{i}} = \\sum_{ij}{(-1)^i\\delta_{ij} \\ket{j} \\bra{i}} = \\sum_{i}{(-1)^i \\ket{i} \\bra{i}}$$ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c12eaf-a120-4a67-a5a2-6a712dc23010",
   "metadata": {},
   "source": [
    "### Exercise 2.10 (page 68):\n",
    "\n",
    "Suppose $\\ket{v_i}$ is an orthonormal basis. What is the martix representation for the operator $A = \\ket{v_j}\\bra{v_k}$\n",
    "\n",
    "\n",
    "$\\ket{v_j}\\bra{v_k}$ maps $\\ket{v_i}$ to $0$ if $i \\ne k$, otherwise it is mapped to $\\ket{v_j}$. This means all columns are $0$ if  $i \\ne k$, otherwise, for the $i = k$ case, we have the matrix representation of $\\ket{v_j}$\n",
    "\n",
    "$$A\\ket{v_i} = \\ket{v_j}\\braket{v_k}{v_i} = \\sum_{l}{A_{li}\\ket{v_l}} = \\ket{v_j}\\delta_{ki}$$\n",
    "\n",
    "That is $A_{jk} = 1$ and $A_{ab} = 0$ otherwise.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0040ef-bbcd-4d58-add7-6fc69da86828",
   "metadata": {},
   "source": [
    "### Exercise 2.11 (page 69): (Eigendecomposition of Pauli matrices)\n",
    "\n",
    "Find the eigenvectors, eigenvalues, and diagonal representation of the Pauli matrices.\n",
    "\n",
    "In Exercise 2.9 we calculated:\n",
    "\n",
    "$$\\sigma_0 = \\sum_{i}{\\ket{i} \\bra{i}} = \\sum_{i}{\\lambda_i \\ket{i} \\bra{i}}, \\lambda_i = 1$$\n",
    "\n",
    "$$\\sigma_3 = \\sum_{i}{\\lambda_i \\ket{i} \\bra{i}}, \\lambda_i = (-1)^i$$ \n",
    "\n",
    "Recall $\\ket{+} = \\frac{\\ket{0} + \\ket{1}}{\\sqrt{2}}$ and $\\ket{-} = \\frac{\\ket{0} - \\ket{1}}{\\sqrt{2}}$\n",
    "\n",
    "$$\\sigma_1 = \\begin{bmatrix} 0 && 1\\\\ 1 && 0\\end{bmatrix}$$\n",
    "\n",
    "Clearly, $\\ket{+}$, $\\ket{-}$ are eigenvectors with respective eigenvalues $\\lambda = 1$ and $\\lambda = -1$, so $$\\sigma_1 = \\ket{+} \\bra{+} - \\ket{-} \\bra{-}$$\n",
    "\n",
    "\n",
    "$$\\sigma_2 = \\begin{bmatrix} 0 && -i\\\\ i && 0\\end{bmatrix}$$\n",
    "\n",
    "To find the eigenvalues $\\lambda$ and eigenvectors $v$, we want:\n",
    "\n",
    "$$\\sigma_2 v = \\lambda v = \\lambda I v$$\n",
    "\n",
    "$$ (\\sigma_2 - \\lambda I)v = 0 $$\n",
    "\n",
    "In order for there to be non-trivial solutions to this, $(\\sigma_2 - \\lambda I)$ must be non-full-rank (a.k.a singular), because full-rank matrices only have a trivial kernel, and therefore its determinant must be zero, because they \"squash\" at least one dimension so the way they transform areas, volumes, etc...\n",
    "\n",
    "$$det(\\sigma_2 - \\lambda I) = \\begin{vmatrix} -\\lambda && -i\\\\ i && -\\lambda\\end{vmatrix} = \\lambda^2 -1 = 0$$\n",
    "\n",
    "therefore $\\lambda =\\pm 1$\n",
    ". To find the eigenvectors, we must find the kernel of the matrix which we do using rref $$\\begin{bmatrix} -\\lambda && -i\\\\ i && -\\lambda\\end{bmatrix} \\rightarrow \\begin{bmatrix} -\\lambda i && 1\\\\ 0 && 0\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "therefore the eigenvectors for this are $$ \\begin{bmatrix} 1 \\\\ \\lambda i \\end{bmatrix} $$ and the outer product rep is $\\sigma_2 = \\ket{a}\\bra{a} - \\ket{b}\\bra{b}$ for $\\ket{a} = \\ket{0} + i \\ket{1}$, $\\ket{b} = \\ket{0} - i \\ket{1}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577a755-9815-4a2e-8370-7a580a3d2efb",
   "metadata": {},
   "source": [
    "### Exercise 2.12 (page 69):\n",
    "Prove that the matrix $A = \\begin{bmatrix} 1 && 0\\\\ 1 && 1\\end{bmatrix}$ is not diagonalizable\n",
    "\n",
    "The eigenvalue for this matrix is $1$ with an algebraic multiplicity of 2. Only $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ is an eigenvector, which means it is not diagonalizable, since we need an orthonormal basis made up of eigenvectors of $A$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf58a8-53a7-4ca5-aae7-659cf63de156",
   "metadata": {},
   "source": [
    "### Exercise 2.13 (page 70):\n",
    "Show $(\\ket{w}\\bra{v})^\\dagger = \\ket{v}\\bra{w} = A^\\dagger$\n",
    "\n",
    "($\\ket{a}$, $A\\ket{b}$) = ($\\ket{a}$, $\\ket{w}\\braket{v}{b}$) = ($\\braket{w}{a}$, $\\braket{v}{b}$) = ($\\ket{v}\\braket{w}{a}$, $\\ket{b}$) = ($A^\\dagger\\ket{a}$, $\\ket{b}$)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237775d1-39b1-4030-84f1-698f38f24810",
   "metadata": {},
   "source": [
    "### Exercise 2.14 (page 70): (Anti-linearity of adjoint)\n",
    "Show the adjoint operation is anti-linear. That is,\n",
    "\n",
    "$$(\\sum_{i}{a_iA_i})^\\dagger = \\sum_{i}{a_i^*A_i^\\dagger}$$\n",
    "\n",
    "($\\ket{v}$, $(\\sum_{i}{a_iA_i})\\ket{w}$) = $\\sum_{i}{a_i(\\ket{v}, A_i\\ket{w})}$ = $\\sum_{i}{(a_i^*A_i^\\dagger\\ket{v}, \\ket{w})}$ = ($(\\sum_{i}{a_i^*A_i^\\dagger})\\ket{v}$, $\\ket{w}$)\n",
    "\n",
    "Note: for any scalar $a \\in C$, $a^\\dagger = a^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2bfb6a-35e8-48f4-a160-20956b1a1e78",
   "metadata": {},
   "source": [
    "### Exercise 2.15 (page 70):\n",
    "Show $(A^\\dagger)^\\dagger = A$\n",
    "\n",
    "($\\ket{a}$, $A\\ket{b}$) = ($A^\\dagger\\ket{a}$, $\\ket{b}$) = ($\\ket{b}$, $A^\\dagger\\ket{a}$)$^*$ = ($(A^\\dagger)^\\dagger\\ket{b}$, $\\ket{a}$)$^*$ = ($\\ket{a}$, $(A^\\dagger)^\\dagger\\ket{b}$) $\\rightarrow A = (A^\\dagger)^\\dagger$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221e50b-1373-462c-abb2-e79e30e1ff93",
   "metadata": {},
   "source": [
    "### Exercise 2.16 (page 70):\n",
    "Show any projector $P \\equiv \\sum_{i=1}^{k}{\\ket{i}\\bra{i}}$ satisfies the equation $P^2 = P$\n",
    "\n",
    "$P^2 = (\\sum_{i=1}^{k}{\\ket{i}\\bra{i}})(\\sum_{j=1}^{k}{\\ket{j}\\bra{j}}) = \\sum_{ij}{\\ket{i}\\delta_{ij}\\bra{j}} = \\sum_{i}{\\ket{i}\\bra{i}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3af898-51e4-4773-9707-d33ad7028c10",
   "metadata": {},
   "source": [
    "### Exercise 2.17 (page 70):\n",
    "Show that a normal matrix is Hermitian iff it has real eigenvalues.\n",
    "\n",
    "Normal Matrix $A$ implies $A^\\dagger A = A A^\\dagger$.\n",
    "\n",
    "By the spectral decomposition of normal matrices, $A$ is diagonalizable. That is $A = \\sum_{i}{\\lambda_i \\ket{i}\\bra{i}}$ for some eigenbasis $\\ket{i}$:\n",
    "\n",
    "$$A^\\dagger = \\sum_{i}{\\lambda_i^* (\\ket{i}\\bra{i})^\\dagger} = \\sum_{i}{\\lambda_i^* \\ket{i}\\bra{i}}$$\n",
    "\n",
    "If the eigenvalues $\\lambda_i$ are real, $\\lambda_i^* = \\lambda_i$, and $A$ is Hermitian:\n",
    "\n",
    "$$A^\\dagger = \\sum_{i}{\\lambda_i^* (\\ket{i}\\bra{i})^\\dagger} = \\sum_{i}{\\lambda_i \\ket{i}\\bra{i}} = A$$\n",
    "\n",
    "Conversely, if $A$ is Hermitian, $\\lambda_i^* = \\lambda_i$\n",
    "\n",
    "$$A = \\sum_{i}{\\lambda_i \\ket{i}\\bra{i}} = A^\\dagger = \\sum_{i}{\\lambda_i^* (\\ket{i}\\bra{i})^\\dagger} = \\sum_{i}{\\lambda_i^* \\ket{i}\\bra{i}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddfe8b5-0d1f-4001-84d7-a31bb884bc79",
   "metadata": {},
   "source": [
    "### Exercise 2.18 (page 71):\n",
    "Show all eigenvalues of a unitary matrix have modulus 1. That is, can be written in the form $e^{i\\theta}$ for some real $\\theta$.\n",
    "\n",
    "Recall $U^\\dagger U = UU^\\dagger = I$, and $U$ is normal. Therefore $U = \\sum_{i}{\\lambda_i\\ket{i}\\bra{i}}$\n",
    "\n",
    "\n",
    "$$ U^\\dagger U =(\\sum_{i}{\\lambda_i^*\\ket{i}\\bra{i}})(\\sum_{j}{\\lambda_j\\ket{j}\\bra{j}}) = \\sum_{ij}{\\lambda_i^*\\lambda_j\\ket{i}\\delta_{ij}\\bra{j}}$$\n",
    "\n",
    "$$ = \\sum_{i}{\\lambda_i^*\\lambda_i\\ket{i}\\bra{i}} = I = \\sum_{i}{\\ket{i}\\bra{i}} $$\n",
    "\n",
    "$$ \\rightarrow \\lambda_i^*\\lambda_i = 1$$\n",
    "\n",
    "Assume $\\lambda_i = \\alpha e^{i\\theta}$, so $1 = (\\alpha e^{-i\\theta}) (\\alpha e^{i\\theta}) = \\alpha^2 e^{0} = \\alpha^2$, so $\\alpha = 1$, and $\\lambda_i = e^{i\\theta}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950616da-b8ba-4c02-8bba-ec6417114f69",
   "metadata": {},
   "source": [
    "### Exercise 2.19 (page 71): (Pauli matrices: Hermitian and Unitary)\n",
    "Show the Pauli Matrices are Hermitian and Unitary\n",
    "\n",
    "Recall:\n",
    "$$\\sigma_0 = \\begin{bmatrix} 1 && 0\\\\ 0 && 1\\end{bmatrix}$$\n",
    "\n",
    "Showing $\\sigma_0$ is Hermitian:\n",
    "$$\\sigma_0^\\dagger = \\begin{bmatrix} 1 && 0\\\\ 0 && 1\\end{bmatrix}^{*T} = \\begin{bmatrix} 1 && 0\\\\ 0 && 1\\end{bmatrix} = \\sigma_0$$ \n",
    "\n",
    "Showing $\\sigma_0$ is Unitary:\n",
    "$$\\sigma_0^\\dagger \\sigma_0  = I I = I$$\n",
    "\n",
    "Showing $\\sigma_1$ is Hermitian:\n",
    "$$\\sigma_1^\\dagger = \\begin{bmatrix} 0 && 1\\\\ 1 && 0\\end{bmatrix}^{*T} = \\begin{bmatrix} 0 && 1\\\\ 1 && 0\\end{bmatrix} = \\sigma_1$$\n",
    "\n",
    "Showing $\\sigma_1$ is Unitary:\n",
    "$$\\sigma_1^\\dagger \\sigma_1  = \\sigma_1^2 = \\begin{bmatrix} 0 && 1\\\\ 1 && 0\\end{bmatrix} \\begin{bmatrix} 0 && 1\\\\ 1 && 0\\end{bmatrix} = \\begin{bmatrix} 1 && 0\\\\ 0 && 1\\end{bmatrix} = I$$\n",
    "\n",
    "Showing $\\sigma_2$ is Hermitian:\n",
    "$$\\sigma_2^\\dagger = \\begin{bmatrix} 0 && -i\\\\ i && 0\\end{bmatrix}^{*T} = \\begin{bmatrix} 0 && i\\\\ -i && 0\\end{bmatrix}^{T} = \\begin{bmatrix} 0 && -i\\\\ i && 0\\end{bmatrix} = \\sigma_2$$\n",
    "\n",
    "Showing $\\sigma_2$ is Unitary:\n",
    "$$\\sigma_2^\\dagger \\sigma_2  = \\begin{bmatrix} 0 && -i\\\\ i && 0\\end{bmatrix} \\begin{bmatrix} 0 && -i\\\\ i && 0\\end{bmatrix} = I$$\n",
    "\n",
    "Showing $\\sigma_3$ is Hermitian:\n",
    "$$\\sigma_3^\\dagger = \\begin{bmatrix} 1 && 0\\\\ 0 && -1\\end{bmatrix}^{*T} = \\begin{bmatrix} 1 && 0\\\\ 0 && -1\\end{bmatrix} = \\sigma_3$$\n",
    "\n",
    "Showing $\\sigma_3$ is Unitary:\n",
    "$$\\sigma_3^\\dagger \\sigma_3 = \\begin{bmatrix} 1 && 0\\\\ 0 && -1\\end{bmatrix} \\begin{bmatrix} 1 && 0\\\\ 0 && -1\\end{bmatrix} = I$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32cfdf0-359a-48ed-931d-06f1a4c79c6b",
   "metadata": {},
   "source": [
    "### Exercise 2.20 (page 71): (Basis Change)\n",
    "\n",
    "Suppose $A'$ and $A''$ are matrix representations of an operator $A$ on a vector space $V$ with respect to two different orthonormal bases, $\\ket{v_i}$ and $\\ket{w_i}$. Characterize the relationship between $A'$ and $A''$.\n",
    "\n",
    "Note $A_{ij}' = \\bra{v_i}A\\ket{v_j}$ and $A_{ij}'' = \\bra{w_i}A\\ket{w_j}$\n",
    "\n",
    "$$A'' = S^{-1} A' S $$\n",
    "\n",
    "where $S$ is know as the change of basis matrix from the $\\ket{w_i}$ basis to the $\\ket{v_i}$ basis. We show $S$ is Unitary, so $S^{-1} = S^\\dagger$:\n",
    "\n",
    "$$S_{ij} = \\braket{v_i}{w_j}$$\n",
    "$$S_{ij}^\\dagger = \\braket{v_j}{w_i}^* = \\braket{w_i}{v_j}$$\n",
    "\n",
    "$(S^\\dagger S)_{ij} = \\sum_{k}{S_{ik}^\\dagger S_{kj}} = \\sum_{k}{\\braket{w_i}{v_k}\\braket{v_k}{w_j}} = \\bra{w_i}(\\sum_{k}{\\ket{v_k}\\bra{v_k}})\\ket{w_j} = \\braket{w_i}{w_j} = \\delta_{ij}$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$A_{ij}'' = \\sum_{kl}{S_{il}^\\dagger A_{lk}' S_{kj}} = \\sum_{kl}{\\braket{w_i}{v_l} \\bra{v_l}A\\ket{v_k} \\braket{v_k}{w_j}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111e649-dc2e-4e76-8fd6-1208d89b215f",
   "metadata": {},
   "source": [
    "### Exercise 2.21 (page 71): (Prove Hermitian Matrices are diagonalizable)\n",
    "\n",
    "Given operator $M = M^\\dagger$, which operators on a vector space $V$, we prove $M$ is diagonalizable. We do this by induction.\n",
    "\n",
    "The base case is $d=1$ is trivial.\n",
    "\n",
    "Let $\\lambda$ be an eigenvalue of $M$. Let $P$ be the projector onto the $\\lambda$ eigenspace, and $Q$ be the projector to the orthogonal complement.\n",
    "\n",
    "Therefore $M = (P + Q)M(P + Q) = PMP + PMQ + QMP + QMQ$\n",
    "\n",
    "$$PMP = \\lambda P$$\n",
    "$$QMP = 0$$\n",
    "$$(PMQ)^\\dagger = QMP = 0$$\n",
    "$$PMQ = (QMP)^\\dagger = 0$$\n",
    "\n",
    "$$M = (P + Q)M(P + Q) = \\lambda P + QMQ$$\n",
    "\n",
    "$(QMQ)^\\dagger = Q^\\dagger M^\\dagger Q^\\dagger = QMQ$, so $QMQ$ is also Hermitian. It follows, by induction $QMQ$ is also diagonalizable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19bcff0-5f06-41ca-afcd-0f80f81da0c8",
   "metadata": {},
   "source": [
    "### Exercise 2.22 (page 71): \n",
    "Prove that two eigenvectors of a Hermitian operator $H = H^\\dagger$ with different eigenvalues are necessarily orthogonal\n",
    "\n",
    "$$H\\ket{v_a} = \\lambda_a \\ket{v_a}$$\n",
    "$$H\\ket{v_b} = \\lambda_b \\ket{v_b}$$\n",
    "\n",
    "Where $\\lambda_a \\ne \\lambda_b$\n",
    "\n",
    "$$ (\\ket{v_a}, H\\ket{v_b}) = (H\\ket{v_a}, \\ket{v_b}) = (\\ket{v_a}, \\lambda_b \\ket{v_b}) = (\\lambda_a \\ket{v_a}, \\ket{v_b})$$\n",
    "\n",
    "$$ \\lambda_b (\\ket{v_a}, \\ket{v_b}) = \\lambda_a^* (\\ket{v_a}, \\ket{v_b})$$\n",
    "\n",
    "Which can only be true if $(\\ket{v_a}, \\ket{v_b}) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630043d1-a3ad-4b5f-9c6e-3b6714904593",
   "metadata": {},
   "source": [
    "### Exercise 2.23 (page 71): \n",
    "Show that the eigenvalues of a projector $P$ are all either $0$ or $1$.\n",
    "\n",
    "Recall the definition of the projector where $k < d$, and $d$ is the dimensionality of the vector space $V$ on which $P$ operates:\n",
    "\n",
    "$$P \\equiv \\sum_{i}^k{\\ket{v_i}\\bra{v_i}}$$\n",
    "\n",
    "Recall also $P$ is Hermitian. Therefore, by the spectral theorem, it is diagonalizable. That is, there exists an outer-product representation $P = \\sum_{i}^d{\\lambda_i\\ket{v_i}\\bra{v_i}}$\n",
    "\n",
    "Therefore:\n",
    "$$\\sum_{i}^d{\\lambda_i\\ket{v_i}\\bra{v_i}} = \\sum_{i}^k{\\ket{v_i}\\bra{v_i}}$$\n",
    "\n",
    "Clearly $\\lambda_j = 0$ for $j > k$, and $\\lambda_j = 1$ for $j < k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56155c04-70c8-4b28-a2f4-c3cde8d20d87",
   "metadata": {},
   "source": [
    "### Exercise 2.24 (page 71): (Hermiticity of positive operators)\n",
    "Show that a positive operator is necessarily Hermitian.\n",
    "\n",
    "The following are true of any operator $A$:\n",
    "$$(\\ket{v}, A\\ket{v}) = (A\\ket{v}, \\ket{v})^* = (A^\\dagger \\ket{v}, \\ket{v})$$\n",
    "\n",
    "Recall a positive operator $A$ is one for which $(\\ket{v}, A\\ket{v}) \\ge 0$ and $(\\ket{v}, A\\ket{v}) \\in R$. Therefore the expression $(\\ket{v}, A\\ket{v}) = (A\\ket{v}, \\ket{v})^* = (A\\ket{v}, \\ket{v}) \\rightarrow A = A^\\dagger$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42225b3-4d85-4dfa-80d8-1260249ddf75",
   "metadata": {},
   "source": [
    "### Exercise 2.25 (page 71):\n",
    "Show that for any operator $A$, $A^\\dagger A$ is positive:\n",
    "\n",
    "$(\\ket{v}, A^\\dagger A \\ket{v}) = (A \\ket{v}, A \\ket{v}) \\ge 0$ by definition of inner product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f7d15-9378-41dd-ba1e-605ffc799c73",
   "metadata": {},
   "source": [
    "### Exercise 2.26 (page 74):\n",
    "Let $\\ket{\\psi} = (\\ket{0} + \\ket{1})/\\sqrt(2) = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $, write $\\ket{\\psi}^{\\otimes 2}$ and $\\ket{\\psi}^{\\otimes 3}$ in terms of tensor products and in terms of Kronecker product\n",
    "\n",
    "$$\\ket{\\psi}^{\\otimes 2} = \\ket{\\psi}\\ket{\\psi} = \\frac{\\ket{0}\\ket{0} + \\ket{0}\\ket{1} + \\ket{1}\\ket{0} + \\ket{1}\\ket{1}}{2} = \\frac{1}{2} \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "$$\\ket{\\psi}^{\\otimes 3} = \\ket{\\psi}\\ket{\\psi}\\ket{\\psi} = \\frac{\\ket{0}\\ket{0}\\ket{0} + \\ket{0}\\ket{0}\\ket{1} + \\ket{0}\\ket{1}\\ket{0} + \\ket{0}\\ket{1}\\ket{1} + \\ket{1}\\ket{0}\\ket{0} + \\ket{1}\\ket{0}\\ket{1} + \\ket{1}\\ket{1}\\ket{0} + \\ket{1}\\ket{1}\\ket{1}}{2\\sqrt{2}} = \\frac{1}{2\\sqrt{2}} \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe7bd6-28a1-483e-8fd5-a5e2d3f60e14",
   "metadata": {},
   "source": [
    "### Exercise 2.27 (page 74):\n",
    "Calculate the matrix representation of the tensor products of.\n",
    "* $X\\otimes Z$\n",
    "* $I\\otimes X$\n",
    "* $X\\otimes I$\n",
    "\n",
    "\n",
    "$$X\\otimes Z =  \\begin{bmatrix} 0 && 1\\\\ 1 && 0\\end{bmatrix} \\otimes Z = \\begin{bmatrix} 0 && Z\\\\ Z && 0\\end{bmatrix} = \\begin{bmatrix} 0 && 0 && 1 && 0\\\\ 0 && 0 && 0 && -1\\\\ 1 && 0 && 0 && 0\\\\ 0 && -1 && 0 && 0\\end{bmatrix}$$\n",
    "\n",
    "$$I\\otimes X =  \\begin{bmatrix} 1 && 0\\\\ 0 && 1\\end{bmatrix} \\otimes X = \\begin{bmatrix} X && 0\\\\ 0 && X\\end{bmatrix} = \\begin{bmatrix} 0 && 1 && 0 && 0\\\\ 1 && 0 && 0 && 0\\\\ 0 && 0 && 0 && 1\\\\ 0 && 0 && 1 && 0\\end{bmatrix}$$\n",
    "\n",
    "$$X\\otimes I =  \\begin{bmatrix} 0 && 1\\\\ 1 && 0\\end{bmatrix} \\otimes I = \\begin{bmatrix} 0 && I\\\\ I && 0\\end{bmatrix} = \\begin{bmatrix} 0 && 0 && 1 && 0\\\\ 0 && 0 && 0 && 1\\\\ 1 && 0 && 0 && 0\\\\ 0 && 1 && 0 && 0\\end{bmatrix}$$\n",
    "\n",
    "Clearly, the tensor product does not commute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7b58e-5bd5-4016-aeb7-352112f22c2b",
   "metadata": {},
   "source": [
    "### Exercise 2.28 (page 74):\n",
    "Show that the transpose, complex conjugation, and adjoint operations distribute over the tensor product. That is, prove:\n",
    "\n",
    "* $(A \\otimes B)^* = A^* \\otimes B^*$\n",
    "* $(A \\otimes B)^T = A^T \\otimes B^T$\n",
    "* $(A \\otimes B)^\\dagger = A^\\dagger \\otimes B^\\dagger$\n",
    "\n",
    "Suppose the matrix representation of $A \\in \\mathbb{R}^{n\\times m}$ and $B \\in \\mathbb{R}^{o\\times p}$\n",
    "  \n",
    "Then, since $a^*b^* = (ab)^*$ for  $a,b \\in \\mathbb{C} \\rightarrow a^*B^* = (aB)^*$:\n",
    "$$(A \\otimes B)^* = \\begin{bmatrix} (A_{11}B)^* && (A_{12}B)^* && ... && (A_{1m}B)^* \\\\ (A_{21}B)^* && (A_{22}B)^* && ... && (A_{2m}B)^* \\\\ \\vdots && \\vdots && \\vdots && \\vdots\\\\ (A_{n1}B)^* && (A_{n2}B)^* && ... && (A_{nm}B)^*\\end{bmatrix} = \\begin{bmatrix} A_{11}^*B^* && A_{12}^*B^* && ... && A_{1m}^*B^* \\\\ A_{21}^*B^* && A_{22}^*B^* && ... && A_{2m}^*B^* \\\\ \\vdots && \\vdots && \\vdots && \\vdots\\\\ A_{n1}^*B^* && A_{n2}^*B^* && ... && A_{nm}^*B^*\\end{bmatrix} = A^* \\otimes B^*$$\n",
    "\n",
    "$$(A \\otimes B)^T = \n",
    "\\begin{bmatrix} \n",
    "A_{11}B_{11} && ...    && A_{11}B_{1p}    && A_{12}B_{11} && ...    && A_{1m}B_{1p} \\\\\n",
    "\\vdots       && \\vdots && \\vdots          && \\vdots       && ...    && \\vdots \\\\\n",
    "A_{11}B_{o1} && ...    && A_{11}B_{op}    && A_{12}B_{o1} && ...    && A_{1m}B_{op} \\\\\n",
    "A_{21}B_{11} && ...    && A_{21}B_{1p}    && A_{22}B_{11} && ...    && A_{2m}B_{1p} \\\\\n",
    "\\vdots       && \\vdots && \\vdots          && \\vdots       && \\vdots && \\vdots \\\\\n",
    "A_{n1}B_{o1} && ...    && A_{n1}B_{op}    && A_{n2}B_{o1} && ...    && A_{nm}B_{op}\n",
    "\\end{bmatrix}^T =\n",
    "\\begin{bmatrix} \n",
    "A_{11}B_{11} && ...    && A_{11}B_{o1}    && A_{21}B_{11} && ...    && A_{n1}B_{o1} \\\\\n",
    "\\vdots       && \\vdots && \\vdots          && \\vdots       && ...    && \\vdots \\\\\n",
    "A_{11}B_{1p} && ...    && A_{11}B_{op}    && A_{21}B_{1p} && ...    && A_{n1}B_{op} \\\\\n",
    "A_{12}B_{11} && ...    && A_{12}B_{o1}    && A_{22}B_{11} && ...    && A_{n2}B_{o1} \\\\\n",
    "\\vdots       && \\vdots && \\vdots          && \\vdots       && \\vdots && \\vdots \\\\\n",
    "A_{1m}B_{1p} && ...    && A_{1m}B_{op}    && A_{2m}B_{1p} && ...    && A_{nm}B_{op}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "A_{11}B^T && A_{21}B^T && ...    && A_{n1}B^T \\\\\n",
    "A_{12}B^T && A_{22}B^T && ...    && A_{n2}B^T \\\\\n",
    "\\vdots    && \\vdots    && \\vdots && \\vdots\\\\\n",
    "A_{1m}B^T && A_{2m}B^T && ...    && A_{nm}B^T\n",
    "\\end{bmatrix} = A^T \\otimes B^T$$\n",
    "\n",
    "Lastly, since $M^\\dagger = (M^T)^* \\rightarrow (A \\otimes B)^\\dagger = ((A \\otimes B)^T)^* = (A^T \\otimes B^T)^* = (A^T)^* \\otimes (B^T)^* = A^\\dagger \\otimes B^\\dagger$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb91401-db38-4d29-9397-074ca53e795c",
   "metadata": {},
   "source": [
    "### Exercise 2.29 (page 74): (Tensor product of Unitary operators is Unitary)\n",
    "Show the tensor product of two unitary operators is unitary.\n",
    "\n",
    "That is, $A^\\dagger A = I = B^\\dagger B \\rightarrow (A \\otimes B)^\\dagger (A \\otimes B) = I $\n",
    "\n",
    "$$(A \\otimes B)^\\dagger (A \\otimes B) =  (A^\\dagger \\otimes B^\\dagger)(A \\otimes B) = A^\\dagger A \\otimes B^\\dagger B = I_{V_A} \\otimes I_{V_B} = I$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb264b-d80e-45ea-9f64-1a74bda63e1c",
   "metadata": {},
   "source": [
    "### Exercise 2.30 (page 74): (Tensor product of Hermitian operators is Hermitian)\n",
    "Show that, given $A^\\dagger = A$, and $B^\\dagger = B \\rightarrow A \\otimes B = (A \\otimes B)^\\dagger$\n",
    "\n",
    "Given the results from exercise 2.28:\n",
    "\n",
    "$(A \\otimes B)^\\dagger = A^\\dagger \\otimes B^\\dagger = A \\otimes B$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ec4ece-de3f-4b25-b2f7-26ed9175d399",
   "metadata": {},
   "source": [
    "### Exercise 2.31 (page 74): (Tensor product of positive operators is positive)\n",
    "Show that, given two positive operators $A$ and $B$, that $A \\otimes B$ is positive.\n",
    "\n",
    "$(\\ket{a} \\otimes \\ket{b}, (A \\otimes B)\\ket{a} \\otimes \\ket{b}) = (\\ket{a} \\otimes \\ket{b},A\\ket{a} \\otimes B\\ket{b}) = (\\ket{a}, A \\ket{a})(\\ket{b}, B\\ket{b}) \\ge 0$ and $(\\ket{a}, A \\ket{a})(\\ket{b}, B\\ket{b}) \\in \\mathbb{R}$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a58ab-b5fa-44f4-8285-e58930a69ad1",
   "metadata": {},
   "source": [
    "### Exercise 2.32 (page 74): (Tensor product of two projectors is a projector)\n",
    "Show that, given two projection operators $A$ and $B$, that $A \\otimes B$ is a projector.\n",
    "\n",
    "$A = \\sum_{i}{\\ket{i}\\bra{i}}$ and $B = \\sum_{j}{\\ket{j}\\bra{j}}$\n",
    "\n",
    "$A \\otimes B = \\sum_{ij}{\\ket{i}\\bra{i} \\otimes \\ket{j}\\bra{j}} = \\sum_{ij}{(\\ket{i} \\otimes \\ket{j})  (\\bra{i} \\otimes \\bra{j}}) = \\sum_{ij}{\\ket{ij}\\bra{ij}}$.\n",
    "\n",
    "By construction $\\ket{ij}$ forms an orthonormal basis on the new vector space, and thus $A \\otimes B$ is a projector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217874e3-1ae5-48a8-92b6-d3aecdea9070",
   "metadata": {},
   "source": [
    "### Exercise 2.33 (page 74):\n",
    "Show explicitly that the Hadamard transform on $n$ qubits, $H^{\\otimes n}$ maybe written as\n",
    "\n",
    "$$ H^{\\otimes n} =  \\frac{1}{\\sqrt{2^n}} \\sum_{x,y}{(-1)^{x \\cdot y}\\ket{x}\\bra{y}}$$\n",
    "\n",
    "and write out an explicit matrix rep for $H^{\\otimes 2}$.\n",
    "\n",
    "Recall $x \\cdot y$ is the bitwise inner product of $x$ and $y$ modulo 2. Recall also that $(\\ket{a} \\otimes \\ket{b})(\\ket{c} \\otimes \\ket{d}) = \\ket{a}\\ket{c} \\otimes \\ket{b}\\ket{c}$\n",
    "\n",
    "$$ H = \\frac{1}{\\sqrt{2}}[(\\ket{0} + \\ket{1})\\bra{0} + (\\ket{0} - \\ket{1})\\bra{1}] = \\frac{1}{\\sqrt{2}} (\\ket{0}\\bra{0} + \\ket{1}\\bra{0} + \\ket{0}\\bra{1} - \\ket{1}\\bra{1}) = \\frac{1}{\\sqrt{2}}\\sum_{x,y}{(-1)^{x\\cdot y}\\ket{x}\\bra{y}} $$\n",
    "\n",
    "$$ H \\otimes H = \\frac{1}{\\sqrt{2}}\\sum_{x,y}{(-1)^{x\\cdot y}\\ket{x}\\bra{y}} \\otimes \\frac{1}{\\sqrt{2}}\\sum_{x,y}{(-1)^{x\\cdot y}\\ket{x}\\bra{y}} $$\n",
    "\n",
    "$$ H \\otimes H = \\frac{1}{2}\\sum_{x_1,y_1,x_2,y_2}{(-1)^{x_1 \\cdot y_1 + x_2 \\cdot y_2}\\ket{x_1}\\ket{x_2} \\bra{y_1}\\bra{y_2}} $$\n",
    "\n",
    "If we relabel $\\ket{x_1}\\ket{x_2} = \\ket{x}$, then $H \\otimes H = \\frac{1}{2}\\sum_{x, y}{(-1)^{x \\cdot y}\\ket{x}\\bra{y}}$\n",
    "\n",
    "In general,\n",
    "\n",
    "$$H^{\\otimes n} = \\frac{1}{\\sqrt{2^n}} \\sum_{x, y}{(-1)^{x \\cdot y}\\ket{x}\\bra{y}} $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09034841-a16f-4843-a3c8-8904c1c06796",
   "metadata": {},
   "source": [
    "### Exercise 2.34 (page 75):\n",
    "Find the $\\sqrt{A}$ and $\\log{A}$ of the matrix below. Clearly the matrix is normal since it is symmetric and has only real entries.\n",
    "\n",
    "$$A = \\begin{bmatrix} 4 && 3\\\\ 3 && 4\\end{bmatrix}$$\n",
    "\n",
    "To find its eigenvalues and eigenvectors, we must find $det(A - \\lambda I) = 0 \\rightarrow (4 - \\lambda)^2 = 9 \\rightarrow \\lambda = 1, 7$.\n",
    "\n",
    "To find the eigenvectors:\n",
    "\n",
    "$$\\begin{bmatrix} 3 && 3\\\\ 3 && 3\\end{bmatrix} v_{\\lambda_1} = 0 \\rightarrow v_{\\lambda_1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}1 \\\\ -1 \\end{bmatrix}$$\n",
    "\n",
    "$$\\begin{bmatrix} -3 && 3\\\\ 3 && -3\\end{bmatrix} v_{\\lambda_2} = 0 \\rightarrow v_{\\lambda_2} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}1 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "$$\\sqrt{A} = \\frac{\\sqrt{1}}{2}\\begin{bmatrix}1 \\\\ -1 \\end{bmatrix}\\begin{bmatrix}1 && -1 \\end{bmatrix} + \\frac{\\sqrt{7}}{2}\\begin{bmatrix}1 \\\\ 1 \\end{bmatrix}\\begin{bmatrix}1 && 1 \\end{bmatrix} = \\frac{1}{2}\\begin{bmatrix}1 && -1 \\\\ -1 && 1 \\end{bmatrix} + \\frac{\\sqrt{7}}{2}\\begin{bmatrix}1 && 1 \\\\ 1 && 1 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "$$\\log{A} = \\frac{\\log{1}}{2}\\begin{bmatrix}1 \\\\ -1 \\end{bmatrix}\\begin{bmatrix}1 && -1 \\end{bmatrix} + \\frac{\\log{7}}{2}\\begin{bmatrix}1 \\\\ 1 \\end{bmatrix}\\begin{bmatrix}1 && 1 \\end{bmatrix} = \\frac{\\log{7}}{2}\\begin{bmatrix}1 && 1 \\\\ 1 && 1 \\end{bmatrix} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e16c3ff-097e-4cab-baeb-bf1268586ac7",
   "metadata": {},
   "source": [
    "### Exercise 2.35 (page 75):\n",
    "Let $\\vec{v}$ be any real, three-dimensional unit vector and $\\theta$ a real number. Prove that\n",
    "\n",
    "$$ \\exp{(i\\theta \\vec{v} \\cdot \\vec{\\sigma})} = \\cos{(\\theta)}I + i\\sin{(\\theta)} \\vec{v} \\cdot \\vec{\\sigma} $$\n",
    "\n",
    "where $\\vec{v} \\cdot \\vec{\\sigma} = \\sum_{i=1}^{3}{v_i\\sigma_i}$\n",
    "\n",
    "\n",
    "$$\\sum_{i=1}^{3}{v_i\\sigma_i} = v_1 \\begin{bmatrix} 0 && 1\\\\ 1 && 0\\end{bmatrix} +  v_2 \\begin{bmatrix} 0 && -i\\\\ i && 0\\end{bmatrix} +  v_3 \\begin{bmatrix} 1 && 0\\\\ 0 && -1\\end{bmatrix} = \\begin{bmatrix} v_3 && v_1 - i v_2\\\\ v_1 + i v_2 && -v_3\\end{bmatrix}$$\n",
    "\n",
    "Note that the sum of Hermitian matrices is Hermitian, and since Hermitian matrices are normal, this matrix has a spectral decomposition. We find the eigenvalues:\n",
    "\n",
    "$$\\begin{vmatrix} v_3 - \\lambda && v_1 - i v_2\\\\ v_1 + i v_2 && -v_3 - \\lambda \\end{vmatrix} = 0 \\rightarrow (v_3 - \\lambda)(-v_3 - \\lambda) - (v_1 - i v_2)(v_1 + i v_2) = 0 \\rightarrow \\lambda^2 = v_1^2 + v_2^2 + v_3^2 \\rightarrow \\lambda = \\pm 1$$\n",
    "\n",
    "Note we need not calculate the eigenvectors. We simply label them $\\ket{a}$ and $\\ket{b}$ such that $\\vec{v} \\cdot \\vec{\\sigma} = \\ket{a}\\bra{a} - \\ket{b}\\bra{b}$\n",
    "\n",
    "Therefore, since $e^{i\\theta} = \\cos{\\theta} + i\\sin{\\theta}$:\n",
    "$$\\exp{(i\\theta \\vec{v} \\cdot \\vec{\\sigma})} = ((\\cos{(\\theta)} + i\\sin{(\\theta)}) \\ket{a}\\bra{a}) + ((\\cos{(\\theta)} - i\\sin{(\\theta)}) \\ket{b}\\bra{b}) = \\cos{(\\theta)} (\\ket{a}\\bra{a} + \\ket{b}\\bra{b}) + (i\\sin{(\\theta)}) (\\ket{a}\\bra{a} - \\ket{b}\\bra{b}) = \\cos{(\\theta)}I + i\\sin{(\\theta)}\\vec{v} \\cdot \\vec{\\sigma}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f689a-a90c-42df-a0f1-c7dd3b4bc270",
   "metadata": {},
   "source": [
    "### Exercise 2.36 (page 76):\n",
    "Show that the Pauli matrices except for $I$ have trace zero.\n",
    "\n",
    "$tr(\\sigma_1) = tr(\\sigma_2) = 0$ because they only have zero on their diagonals. $tr(\\sigma_3) = 1 - 1 = 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a3b535-293d-4282-a59d-6dc840a7d6ee",
   "metadata": {},
   "source": [
    "### Exercise 2.37 (page 76): (Cyclic property of the trace)\n",
    "Show, if $A$ and $B$ are two linear operators, that\n",
    "\n",
    "$$tr(AB) = tr(BA)$$\n",
    "\n",
    "Recall\n",
    "$$(AB)_{ij} = \\sum_k{A_{ik}B_{kj}}$$\n",
    "\n",
    "And\n",
    "$$tr(A) = \\sum_i{A_{ii}}$$\n",
    "\n",
    "Therefore\n",
    "$$tr(AB) = \\sum_i{\\sum_k{A_{ik}B_{ki}}} = \\sum_k{\\sum_i{B_{ki}A_{ik}}} = tr(BA)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae5dc3-b20c-4e10-9fbe-f5d52eda423b",
   "metadata": {},
   "source": [
    "### Exercise 2.38 (page 76): (Linearity of the trace)\n",
    "\n",
    "Show $tr(A + B) = tr(A) + tr(B)$ and $tr(zA) = z*tr{A}$ for $z \\in \\bf{C}$\n",
    "\n",
    "$$tr(zA) = \\sum_i{z A_{ii}} = z \\sum_i{A_{ii}} = z*tr(A)$$\n",
    "\n",
    "$$tr(A) + tr(B) = \\sum_i{A_{ii}} + \\sum_i{B_{ii}} = \\sum_i{A_{ii} + B_{ii}} = tr(A + B)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e895b-7109-48f9-99c7-18033d0397b5",
   "metadata": {},
   "source": [
    "### Exercise 2.39 (page 76): (The Hilbert-Schmidt inner product on operators)\n",
    "The set $L_V$ of linear operators on a Hilbert space $V$ is a vector space. It also has a natural inner product, which makes it a Hilbert space itself.\n",
    "\n",
    "(1) Show (., .) on $L_V \\times L_V$ defined by $(A, B) = tr(A^\\dagger B)$ is an inner product function. This is known as the Hilbert-Schmidt or trace inner product.\n",
    "\n",
    "(2) Show if $V$ has $d$ dimensions then $L_V$ has dimension $d^2$\n",
    "\n",
    "(3) Find an orthonormal basis of Hermitian matrices for the Hilbert space $L_V$\n",
    "\n",
    "Recall the requirements for an inner product are to firstly show linearity in the second argument, which we've trivially shown in exercise 2.38. Secondly, we must show $(A, B) = (B, A)^*$\n",
    "\n",
    "$$(A, B) = tr(A^\\dagger B) = \\sum_i{\\sum_k{A^{*}_{ki} B_{ki}}} = \\sum_i{\\sum_k{(A_{ki} B^{*}_{ki})^*}} = (\\sum_i{\\sum_k{(B^{*T}_{ik} A_{ki})}})^* = (B, A)^*$$\n",
    "\n",
    "Thirdly, and finally, we must show $(A, A) \\ge 0$ with equality iff $A = 0$\n",
    "\n",
    "$$(A, A) = tr(A^\\dagger A) = \\sum_i{\\sum_k{A^{*}_{ki} A_{ki}}} \\ge 0$$\n",
    "\n",
    "If $V$ has $d$ dimensions, then there exists an orthonormal basis $\\ket{i}$ which spans $V$. We can characterize $L_V$ by how each of its basis vectors (i.e. basis linear operators) transform each basis vector of $V$. That is, define linear operator $E_{ij}$ that maps $\\ket{i}$ to $\\ket{j}$. Clearly there are $d^2$ of them. Does it span $L_V$? To show this we must show any arbirary linear transformation $L$, which acts on $V$, can be represented as a linear combination of $E_{ij}$.\n",
    "\n",
    "$$E_{ij} \\ket{i} = \\ket{j}$$\n",
    "\n",
    "Recall any $L$ is defined by its action on a basis $\\ket{i}$.\n",
    "$$L\\ket{i} = \\sum_j{L_{ij}E_{ij}\\ket{i}} \\rightarrow L = \\sum_j{L_{ij}E_{ij}}$$\n",
    "\n",
    "So indeed, $E_{ij}$ spans $L_V$\n",
    "\n",
    "How do we find an orthonormal basis of Hermitian matrices for the Hilber space $L_V$? Best I can come up with is the wiki page [\"Generalizations of Pauli matrices\"](https://en.wikipedia.org/wiki/Generalizations_of_Pauli_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2acb0e-ad46-440d-a6f7-5743263b1f1e",
   "metadata": {},
   "source": [
    "### Exercise 2.40 (page 77): (Commutation relations for the pauli matrices)\n",
    "\n",
    "Verify\n",
    "$$[\\sigma_j, \\sigma_k] = 2i\\sum_{l=1}^3{\\epsilon_{jkl}\\sigma_l}$$\n",
    "\n",
    "That is:\n",
    "* $[X, Y] = 2iZ$\n",
    "* $[Y, Z] = 2iX$\n",
    "* $[Z, X] = 2iY$\n",
    "\n",
    "\n",
    "$$[X, Y] = XY - YX = \\paulix \\pauliy - \\pauliy \\paulix = \\begin{bmatrix} i && 0\\\\ 0 && -i\\end{bmatrix} - \\begin{bmatrix} -i && 0\\\\ 0 && i\\end{bmatrix} = 2iZ$$\n",
    "\n",
    "$$[Y, Z] = YZ - ZY = \\pauliy \\pauliz - \\pauliz \\pauliy = \\begin{bmatrix} 0 && i\\\\ i && 0\\end{bmatrix} - \\begin{bmatrix} 0 && -i\\\\ -i && 0\\end{bmatrix} = 2iX$$\n",
    "\n",
    "$$[Z, X] = ZX - XZ = \\pauliz \\paulix - \\paulix \\pauliz = \\begin{bmatrix} 0 && -1\\\\ 1 && 0\\end{bmatrix} - \\begin{bmatrix} 0 && 1\\\\ -1 && 0\\end{bmatrix} = 2iY$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac947807-2dac-4875-8770-2016d80914fa",
   "metadata": {},
   "source": [
    "### Exercise 2.41 (page 78): (Anti-commutation relations for the pauli matrices)\n",
    "Verify $\\{\\sigma_i, \\sigma_j\\} = 0$ for $i \\ne j$ and $i, j \\in \\{1, 2, 3\\}$.\n",
    "\n",
    "Also verify $\\sigma_i^2 = I$ for $i \\in \\{0, 1, 2, 3\\}$\n",
    "\n",
    "$$ \\{X, Y\\} = XY + YX = \\paulix \\pauliy + \\pauliy \\paulix = \\begin{bmatrix} i && 0\\\\ 0 && -i\\end{bmatrix} + \\begin{bmatrix} -i && 0\\\\ 0 && i\\end{bmatrix} = 0$$\n",
    "\n",
    "$$ \\{Y, Z\\} = YZ + ZY = \\pauliy \\pauliz + \\pauliz \\pauliy = \\begin{bmatrix} 0 && i\\\\ i && 0\\end{bmatrix} + \\begin{bmatrix} 0 && -i\\\\ -i && 0\\end{bmatrix} = 0$$\n",
    "\n",
    "$$ \\{Z, X\\} = ZX + XZ = \\pauliz \\paulix + \\paulix \\pauliz = \\begin{bmatrix} 0 && -1\\\\ 1 && 0\\end{bmatrix} + \\begin{bmatrix} 0 && 1\\\\ -1 && 0\\end{bmatrix} = 0$$\n",
    "\n",
    "$$I^2 = I$$\n",
    "\n",
    "$$X^2 = \\paulix ^2 = \\paulix \\paulix = \\begin{bmatrix} 1 && 0\\\\ 0 && 1\\end{bmatrix} = I$$\n",
    "\n",
    "$$Y^2 = \\pauliy ^2 = \\pauliy \\pauliy = \\begin{bmatrix} 1 && 0\\\\ 0 && 1\\end{bmatrix} = I$$\n",
    "\n",
    "$$Z^2 = \\pauliz ^2 = \\pauliz \\pauliz = \\begin{bmatrix} 1 && 0\\\\ 0 && 1\\end{bmatrix} = I$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e4592-a2f8-4bc6-9818-22aa4fec4138",
   "metadata": {},
   "source": [
    "### Exercise 2.42 (page 78):\n",
    "Verify that\n",
    "\n",
    "$$AB = \\frac{[A, B] + \\{A,B\\}}{2}$$\n",
    "\n",
    "$$AB = [A, B] + BA = [A, B] + \\{A, B\\} - AB$$\n",
    "\n",
    "$$2AB = [A, B] + \\{A, B\\}$$\n",
    "\n",
    "$$AB = \\frac{[A, B] + \\{A,B\\}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1bf7e8-82d9-4acf-aaad-67f3797ba9e0",
   "metadata": {},
   "source": [
    "### Exercise 2.43 (page 78):\n",
    "Show that for $j, k = 1, 2, 3$\n",
    "\n",
    "$$\\sigma_j \\sigma_k = \\delta_{jk}I + i \\sum_{l=1}^3{\\epsilon_{jkl}\\sigma_l}$$\n",
    "\n",
    "For the case where $j=k$, $\\sigma_j^2 = I = \\delta_{jj} I + i \\sum{0} = I$ \n",
    "\n",
    "For the case where $j\\ne k$, $\\sigma_j \\sigma_k = i \\sum_{l=1}^3{\\epsilon_{jkl} \\sigma_l}$\n",
    "\n",
    "Using The result of Exercise 2.42:\n",
    "$$\\sigma_j \\sigma_k = \\frac{[\\sigma_j, \\sigma_k] + \\{\\sigma_j, \\sigma_k\\}}{2} = \\frac{[\\sigma_j, \\sigma_k]}{2} = i\\sum_{l=1}^3{\\epsilon_{jkl}\\sigma_l}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb61535-b134-431e-a465-ed642b6ce022",
   "metadata": {},
   "source": [
    "### Exercise 2.44 (page 78):\n",
    "Suppose $[A, B] = 0$, $\\{A, B\\} = 0$, and $A$ is invertible. Show $B = 0$\n",
    "$$AB = \\frac{[A, B] + \\{A,B\\}}{2} = 0$$\n",
    "\n",
    "$$A^{-1} A B = A^{-1} 0$$\n",
    "\n",
    "$$B = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b122147a-7524-4ba1-b967-6410ebf7a806",
   "metadata": {},
   "source": [
    "### Exercise 2.45 (page 78):\n",
    "Show $[A, B]^\\dagger = [B^\\dagger, A^\\dagger]$\n",
    "\n",
    "$$[A, B]^\\dagger = (AB - BA)^\\dagger = (AB)^\\dagger - (BA)^\\dagger = B^\\dagger A^\\dagger - A^\\dagger B^\\dagger = [B^\\dagger, A^\\dagger]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975a69b-308d-46e9-83f7-088efef729ff",
   "metadata": {},
   "source": [
    "### Exercise 2.46 (page 78):\n",
    "Show $[A, B] = -[B, A]$\n",
    "\n",
    "$$[A, B] = AB - BA = - (BA - AB) = -[B, A]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ceb8a-e182-47b8-8e29-5eba85766794",
   "metadata": {},
   "source": [
    "### Exercise 2.47 (page 78):\n",
    "Suppose $A$ and $B$ are Hermitian. Show that $i[A, B]$ is Hermitian\n",
    "\n",
    "$A = A^\\dagger$, $B = B^\\dagger$\n",
    "\n",
    "$$(i[A, B])^\\dagger = -i[B^\\dagger, A^\\dagger] = i [A^\\dagger, B^\\dagger] = i [A, B]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213df3f-3de6-48cd-a5dc-cd4c950beeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
